# 第三章-线性模型

## 基本形式

给定由 ${d}$ 个属性描述的示例 ${x = (x_1; x_2; \ldots;x_d)}$，其中 ${x_i}$ 是 ${x}$ 在第 ${i}$ 个属性上的取值，线性模型视图学得一个通过属性的线性组合来进行预测的函数，即：

$${f(x) = w_1 x_1 + w_2 x_2 + \ldots + w_d x_d + b}$$，

一般向量形式写成：

$${f(x) = w^T x + b}$$

其中 ${w = (w_1; w_2; \ldots;w_d)}$。${w}$ 和 ${b}$ 学得之后，模型就得以确定。

![](http://ofqm89vhw.bkt.clouddn.com/ccef52ea6e80bebdca98d437e5d762ac.png)

## 线性回归

![视图](http://ofqm89vhw.bkt.clouddn.com/288ca043d8393b05a8692c86bd3c17f0.png)

![MSR](http://ofqm89vhw.bkt.clouddn.com/09d20756398c59a9f11e6884441958a7.png)

![多元线性回归](http://ofqm89vhw.bkt.clouddn.com/0b8245e1bc0ce1d10f4a5dc7164744c7.png)

![矩阵形式](http://ofqm89vhw.bkt.clouddn.com/9d7193fcc084610e8d02da2efce9c637.png)

![求解](http://ofqm89vhw.bkt.clouddn.com/18286176385dff1f17c39fbe2203bb98.png)

![凸函数](http://ofqm89vhw.bkt.clouddn.com/63af924df0040be6c9293c018809b11d.png)

![关于正则化](http://ofqm89vhw.bkt.clouddn.com/8abfdffe27f23f52363314ee72456d80.png)

![对数线性回归](http://ofqm89vhw.bkt.clouddn.com/e53c428bb7556b22d08e72fad9da50b1.png)

![对数](http://ofqm89vhw.bkt.clouddn.com/65ecc33ed3be06201d99ff301a5a19e2.png)

$${\ln y = w^Tx + b}$$

![广义线性模型](http://ofqm89vhw.bkt.clouddn.com/ecb2e6cab60bfb97361d856bf7e3f5ce.png)

## 对数几率回归

![单位阶跃函数与对数几率函数](http://ofqm89vhw.bkt.clouddn.com/f38d2a071f7f24b95ab279ac754c5ae3.png)

单位阶跃函数不连续，因此不能，我们希望能够在一定程度上中找到近似单位阶跃函数的“替代函数”，并且希望它但调控为，对数几率函数正是这样一个常用的替代函数：

$${y = \frac{1}{1 + e^{-z}}}$$

是一种“Sigmoid函数”，它将 ${z}$ 值转换为一个接近 ${}$ 和 ${1}$ 的 ${y}$ 值，并且其输出值在 ${z = 0}$ 附近变化很陡。

$${y = \frac{1}{1 + e^{-(w^T + b)}}}$$

$${\ln \frac{y}{1-y} = w^T + b}$$

若将 ${y}$ 视为样本 ${x}$ 作为正例的可能，则 ${1 - y}$ 是其反例的可能性，则两者的比值为：

$${\frac{y}{1-y}}$$

称为“几率”（odds），反映了x作为正例的相对可能性，对几率取对数则得到“对数几率”（log odds，依称logit）：

$${\ln \frac{y}{1-y}}$$

![分析](http://ofqm89vhw.bkt.clouddn.com/adc6fdcaf9676713b52da652f0506ffc.png)

![概率估计](http://ofqm89vhw.bkt.clouddn.com/af2d7e1e596c5cad8e0fbc0b8a3e6480.png)

![极大似然估计](http://ofqm89vhw.bkt.clouddn.com/56f3d53aba4400e82f7c9f5514d3801d.png)

![优化算法](http://ofqm89vhw.bkt.clouddn.com/6056c9128f2b6e3dd3e138076854f8dc.png)

## 线性判别分析

线性判别分析是一种经典的线性学习方法，思想朴素：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点可能接近、异类样例的投影点尽可能远离；在对新样本来进行分类时，将其投影在同样的一条直线上，再根据投影点的位置来确定新样本的类别。

![LDA示意图](http://ofqm89vhw.bkt.clouddn.com/dc0c5e3f94d05bc61ce9f5ab50581490.png)

## 多分类学习

![分类任务观点](http://ofqm89vhw.bkt.clouddn.com/0e9c973868eb5e5589c3921f45034499.png)

分类任务策略：

1. 一对一。
1. 一对余。
1. 多对多。

![OvO与OvR示意图](http://ofqm89vhw.bkt.clouddn.com/5b128cc972540c69ef85606103ca5297.png)

## 类别不平衡问题

![存在问题](http://ofqm89vhw.bkt.clouddn.com/9599717e0b3aacd3c438b7f6ad6ac5b9.png)

![问题定义](http://ofqm89vhw.bkt.clouddn.com/0031f2c33c09c2f58a511932475e394e.png)

![阈值滑动](http://ofqm89vhw.bkt.clouddn.com/39f33789cf75396a1eabd79e753f325c.png)

在分类任务中，不同类别的样例数目在不同的

![目前的三类做法](http://ofqm89vhw.bkt.clouddn.com/2b847418a72d8f2c65f05ee0b329c357.png)

![](http://ofqm89vhw.bkt.clouddn.com/f8a50dd7a866f6614595b0075965764e.png)

## 阅读材料

“稀疏表示”

## 习题