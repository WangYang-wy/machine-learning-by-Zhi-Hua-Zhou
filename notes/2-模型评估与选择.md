# 第二章-模型评估与选择

## 经验误差与过拟合

![名词解释](http://ofqm89vhw.bkt.clouddn.com/96daf4fce2b4a7acdcd2dc4b611b1829.png)

一般来说，学习器的预测输出和实际真实的输出是有差异的，称为误差。

![过拟合与欠拟合](http://ofqm89vhw.bkt.clouddn.com/37ad87b52a44864c941852c4841c8357.png)

如果学习器学的太差，对训练样本的一般性质没学好，则称为欠拟合 underfitting。

机器学习面临的问题通常是 ${NP}$ 难或者更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性地证明了 ${P=NP}$。因此只要相信 ${P \neq NP}$ ，过拟合就不可避免。

相反，如果学的「太好」，把训练样本自身的一些特点当成了所有潜在样本都具有的一般性质，这种情况称为过拟合 overfitting 。

欠拟合比较容易克服，往往因为学习器学习能力太强大导致的过拟合很难处理，实际上过拟合是机器学习面临的关键障碍。首先必须认识到，过拟合无法避免，我们需要做的是降低或者缓解。

## 评估方法

![评估](http://ofqm89vhw.bkt.clouddn.com/5d2e0f6a8217a0eb1125cc2fe929c7a5.png)

### 留出法

![](http://ofqm89vhw.bkt.clouddn.com/8202dadf74c7b81fba6b2ab1e3274c31.png)

![分层采样](http://ofqm89vhw.bkt.clouddn.com/bf126def916af7f30ae3a62a45265c93.png)

### 交叉验证法

![](http://ofqm89vhw.bkt.clouddn.com/b4299428156c64cce4fc83b3f9235b45.png)

![十折交叉验证示意图](http://ofqm89vhw.bkt.clouddn.com/d99f34f24e88e9146325c7e6c776cf05.png)

![Leave-One-Out](http://ofqm89vhw.bkt.clouddn.com/4564bfde98626d58c93bc360dd277874.png)

### 自助法

![](http://ofqm89vhw.bkt.clouddn.com/d48756c48c2d544e897ad2cda16a3dad.png)

![缺陷](http://ofqm89vhw.bkt.clouddn.com/06f05bc03653c1767bc9485d797eb16b.png)

### 调参与最终模型

## 性能度量

均方误差：

$${E(f;D) = \frac{1}{m} \sum_{i=1}^{m} (f(x_i) - y_i)^2}$$

对于数据分布 ${D}$ 和概率密度函数 ${p(·)}$，均方误差为：

$${E(f;D) = \int_{x \sim D} (f(x) - y)^2 p(x)dx}$$

### 错误率与精度

错误率是分类错误的样本数占样本总数的比例：

$${E(f;D) = \frac{1}{m} \mathbb{I} (f(x_i) \neq y_i)}$$

精度则是分类正确的样本数占总样本数的比例：

$${acc(f;D) = \frac{1}{m} \mathbb{I} (f(x_i) = y_i) = 1 - E(f;D)}$$

更一般的，对于数据分布 ${D}$ 和概率密度函数 ${f(·)}$，错误率与精度可以分别描述为：

$${E(f;D) = \int_{x \sim D} \mathbb{I} (f(x_i) \neq y_i) p(x)dx}$$

$${acc(f;D) = \int_{x \sim D} \mathbb{I} (f(x_i) = y_i) p(x)dx = 1 - E(f;D)}$$

### 查准率与查全率

![分类结果混淆矩阵](http://ofqm89vhw.bkt.clouddn.com/d22fb63797fa1cf813fe0764fbb51ffa.png)

查准率 ${P}$ 与查全率 ${R}$ 分别定义为：

$${P = \frac{TP}{TP + FP}}$$

$${R = \frac{TP}{TP + FN}}$$

![](http://ofqm89vhw.bkt.clouddn.com/bf2e9af42fc1c6bc38f8d8e0674ea585.png)

查准率与查全率是一对矛盾的度量。

![](http://ofqm89vhw.bkt.clouddn.com/847971d3ad10e2bec78f323125406486.png)

1. 偏差：度量学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。
1. 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。
1. 噪声：表达了当前任务下任何学习算法所能达到的期望泛化误差的下限，即刻画了学习问题本身的难度。

![P-R曲线与平衡点示意图](http://ofqm89vhw.bkt.clouddn.com/329a8c75e34e7cd7b13ec26b0ae6364c.png)

![平衡点](http://ofqm89vhw.bkt.clouddn.com/6baceee7a835c621b0f03710541c5de4.png)

平衡点。

![BEP](http://ofqm89vhw.bkt.clouddn.com/ad5a19e85fb5f2971f0fa9eee24bb11b.png)

更常用的是 ${F1}$ 度量：

$${F1 = \frac{2 \times P \times R}{P + R}}$$

${F1}$ 是基于查准率与查全率的调和平均定义的：

$${\frac{1}{F1} = \frac{1}{2} · \Big( \frac{1}{R} + \frac{1}{P} \Big)}$$

### ${ROC}$ 与 ${AUC}$

### 代价铭感错误率与代价曲线

不同类型的错误所造成的后果不同，为了权衡不同类型错误所造成的不同损失，可为错误赋予“非等价代价”（unequal cost）。

以二分类为例，我们可根据任务的领域知识设定一个“代价矩阵”（cost matrix），其中 ${cost_{ij}}$ 表示第 ${i}$ 类样本预测为第 ${j}$ 类样本的代价。

![二分类代价矩阵](http://ofqm89vhw.bkt.clouddn.com/87660a7ccae39b9017bba41b039fdd38.png)

## 比较检验

