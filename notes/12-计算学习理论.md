# 第十二章-计算学习理论

## 基础知识

计算学习理论（computational learning theory）研究的是关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础，其目的是分析学习任务困难的本质，为学习算法提供理论保证，并根据分析结果指导算法设计。

所有样本都是独立同分布的。

几个常用的不等式：

### Jensen 不等式

对任意的凸函数 ${f(x)}$，有：${f(\mathbb{E}) \leq \mathbb{E}(f(x))}$ 。

### Hoeffding 不等式

若 ${x_1, x_2, \ldots, x_m}$ 为 ${m}$ 个独立随机变量，且满足 ${0 \leq x_i \leq 1}$，对任意 ${\epsilon > 0}$，有

$${P \Big(\frac{1}{m} \sum_{i=1}^{m} x_i - \frac{1}{m} \mathbb{E} (x_i) \geq \epsilon \Big) \leq \exp(-2m\epsilon^2)}$$

$${P \Big|(\frac{1}{m} \sum_{i=1}^{m} x_i - \frac{1}{m} \mathbb{E} (x_i) \geq \epsilon \Big| \leq 2\exp(-2m\epsilon^2)}$$

### McDiarmid 不等式

## PAC 学习

概率近似正确。

## 有限假设空间

### 可分情形

## VC维

对可学习性进行研究，需度量假设空间的复杂度。最常见的办法是考虑假设空间的“VC维”。

### 增长函数

### 对分

### 打散

## 稳定性

## 习题