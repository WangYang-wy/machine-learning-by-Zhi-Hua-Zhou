# 第二章-模型评估与选择

## 经验误差与过拟合

![名词解释](http://ofqm89vhw.bkt.clouddn.com/96daf4fce2b4a7acdcd2dc4b611b1829.png)

一般来说，学习器的预测输出和实际真实的输出是有差异的，称为误差。

![过拟合与欠拟合](http://ofqm89vhw.bkt.clouddn.com/37ad87b52a44864c941852c4841c8357.png)

如果学习器学的太差，对训练样本的一般性质没学好，则称为欠拟合 underfitting。

机器学习面临的问题通常是 ${NP}$ 难或者更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性地证明了 ${P=NP}$。因此只要相信 ${P \neq NP}$ ，过拟合就不可避免。

相反，如果学的「太好」，把训练样本自身的一些特点当成了所有潜在样本都具有的一般性质，这种情况称为过拟合 overfitting 。

欠拟合比较容易克服，往往因为学习器学习能力太强大导致的过拟合很难处理，实际上过拟合是机器学习面临的关键障碍。首先必须认识到，过拟合无法避免，我们需要做的是降低或者缓解。

## 评估方法

### 流出法

### 交叉验证法

![十折交叉验证示意图](http://ofqm89vhw.bkt.clouddn.com/d99f34f24e88e9146325c7e6c776cf05.png)

### 自助法

### 调参与最终模型

## 性能度量

均方误差：

$${E(f;D) = \frac{1}{m} \sum_{i=1}^{m} (f(x_i) - y_i)^2}$$

对于数据分布 ${D}$ 和概率密度函数 ${p(·)}$，均方误差为：

$${E(f;D) = \int_{x \sim D} (f(x) - y)^2 p(x)dx}$$

### 错误率与精度

错误率是分类错误的样本数占样本总数的比例：

$${E(f;D) = \frac{1}{m} \mathbb{I} (f(x_i) \neq y_i)}$$

精度则是分类正确的样本数占总样本数的比例：

$${acc(f;D) = \frac{1}{m} \mathbb{I} (f(x_i) = y_i) = 1 - E(f;D)}$$

更一般的，对于数据分布 ${D}$ 和概率密度函数 ${f(·)}$，错误率与精度可以分别描述为：

$${E(f;D) = \int_{x \sim D} \mathbb{I} (f(x_i) \neq y_i) p(x)dx}$$

$${acc(f;D) = \int_{x \sim D} \mathbb{I} (f(x_i) = y_i) p(x)dx = 1 - E(f;D)}$$

### 查准率与查全率

![](http://ofqm89vhw.bkt.clouddn.com/bf2e9af42fc1c6bc38f8d8e0674ea585.png)

![](http://ofqm89vhw.bkt.clouddn.com/847971d3ad10e2bec78f323125406486.png)

1. 偏差：度量学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。
1. 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。
1. 噪声：表达了当前任务下任何学习算法所能达到的期望泛化误差的下限，即刻画了学习问题本身的难度。

![P-R曲线与平衡点示意图](http://ofqm89vhw.bkt.clouddn.com/329a8c75e34e7cd7b13ec26b0ae6364c.png)

![平衡点](http://ofqm89vhw.bkt.clouddn.com/6baceee7a835c621b0f03710541c5de4.png)

平衡点。
